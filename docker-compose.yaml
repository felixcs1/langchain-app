version: "3.8"
services:
  ollama:
    container_name: ollama
    image: ollama/ollama
    volumes:
      - ./models:/root/.ollama
    # # Only to check ollam is running on local host
    ports:
      - 11434:11434
  langserve:
    container_name: langserve
    build:
      context: ./
      dockerfile: Dockerfile
    volumes:
      - ./:/code
    ports:
      - "8080:8080"
    depends_on:
      - ollama



# To get new model into local folder
# docker run --rm -d -p 11434:11434 --name ollama --network ollama-net -v $(pwd)/models:/root/.ollama ollama/ollama
# docker exec -it  ollama ollama run orca-mini:3b
    

# Run with commands
# docker network create ollama-net   
# docker run --rm -d -p 11434:11434 --name ollama --network ollama-net -v $(pwd)/models:/root/.ollama ollama-run 
# docker run --rm  -p 8080:8080 --name langserve --network ollama-net langserve